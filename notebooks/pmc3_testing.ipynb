{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import pickle as pkl\n",
    "import pymc3 as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import arviz as az\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "fp = os.path.abspath('model_set.csv')\n",
    "raw_df = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transforms\n",
    "raw_df[\"LogSalePrice\"] = np.log(raw_df.SalePrice)\n",
    "raw_df.CentralAir = [1 if i == \"Y\" else 0 for i in raw_df.CentralAir]\n",
    "raw_df.YrSold = raw_df.YrSold - raw_df.YrSold.min()  # years from 2006\n",
    "raw_df.YearBuilt = raw_df.YearBuilt - raw_df.YearBuilt.min()  # years from 1872\n",
    "Neighborhoods = raw_df.Neighborhood.unique()\n",
    "NbdLookup = dict(zip(Neighborhoods, range(Neighborhoods.size)))\n",
    "raw_df[\"NeighborhoodCode\"] = raw_df.Neighborhood.replace(NbdLookup)\n",
    "\n",
    "# drop unecessary cols\n",
    "d_cols = [\"Utilities\"]\n",
    "raw_df.drop(columns=d_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-making",
   "metadata": {},
   "outputs": [],
   "source": [
    "### data preparation and formatting ###\n",
    "\n",
    "# design matix\n",
    "covariates = (\"1stFlrSF\", \"LotArea\")\n",
    "y = raw_df.LogSalePrice\n",
    "X = raw_df.loc[:, covariates]\n",
    "X_nbd = raw_df.loc[:, \"NeighborhoodCode\"]\n",
    "n_nbd = Neighborhoods.size\n",
    "n, p = X.shape\n",
    "\n",
    "# train-test split\n",
    "train_idx, test_idx = train_test_split(range(n),\n",
    "                                       test_size=0.2,\n",
    "                                       random_state=1)\n",
    "X_train = X.iloc[train_idx, :].reset_index(drop=True)\n",
    "X_nbd_train = X_nbd.iloc[train_idx].reset_index(drop=True)\n",
    "X_test = X.iloc[test_idx, :].reset_index(drop=True)\n",
    "X_nbd_test = X_nbd.iloc[test_idx].reset_index(drop=True)\n",
    "y_train = y.iloc[train_idx].reset_index(drop=True)\n",
    "y_test = y.iloc[test_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nbd_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_model = pm.Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ip_mat = np.eye(p)\n",
    "zp_vec = np.zeros(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model and perform sampling\n",
    "with hp_model:\n",
    "    X_train_data = pm.Data(\"X_train_data\", X_train)\n",
    "    nbd_idx = pm.Data(\"nbd_idx\", X_nbd_train)\n",
    "    y_train_data = pm.Data(\"y_train_data\", y_train)\n",
    "    # hyper priors\n",
    "    chol, corr, stds = pm.LKJCholeskyCov(\"Omega\", n=p, eta=1.,\n",
    "                                         sd_dist=pm.HalfStudentT.dist(sigma=0.5,\n",
    "                                                                      nu=1.),\n",
    "                                         compute_corr=True)\n",
    "    cov = pm.Deterministic(\"cov\", chol.dot(chol.T))\n",
    "    tau_alpha = pm.HalfStudentT(\"tau_alpha\", sigma=0.5, nu=1.)\n",
    "    alpha = pm.Normal(\"alpha\", mu=12., sigma=0.5)\n",
    "    # priors\n",
    "    alpha_nbd = pm.Normal(\"alpha_nbd\", mu=alpha, sigma=tau_alpha, shape=(n_nbd,))\n",
    "    beta_uc = pm.MvNormal(\"beta_uc\", mu=zp_vec, cov=Ip_mat, shape=(p,))\n",
    "    beta = pm.Deterministic(\"beta\", cov.dot(beta_uc))\n",
    "    sigma = pm.HalfStudentT(\"sigma\", sigma=0.5, nu=1.)\n",
    "    # likelihood\n",
    "    Ey_x = T.add(alpha_nbd[nbd_idx], X_train_data.dot(beta))  # E[Y|X]\n",
    "    y_obs = pm.Normal(\"y_obs\", mu=Ey_x, sigma=sigma, observed=y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(hp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "with hp_model:\n",
    "    posterior = pm.sample(draws=50, tune=200, cores=2,\n",
    "                          init=\"advi+adapt_diag\",\n",
    "                          target_accept=0.95,\n",
    "                          return_inferencedata=False)\n",
    "    posterior_predictive = pm.fast_sample_posterior_predictive(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bpostance.github.io/posts/pymc3-predictions/\n",
    "# example of out-of-sample predictions\n",
    "with bglm:\n",
    "    pm.set_data({\"pred\": testx.T})\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace, var_names=[\"y\"], samples=600)\n",
    "    model_preds = posterior_predictive[\"y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.DataFrame(posterior_predictive[\"y_obs\"].T)\n",
    "t.columns = [f\"sample_{i}\" for i in range(t.shape[1])]\n",
    "t.to_csv(\"./posterior_pred_samps.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(\"./posterior_pred_samps.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_predictive[\"y_obs\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-mediterranean",
   "metadata": {},
   "source": [
    "pm.save_trace(trace=posterior) DONT RUN THIS UNLESS YOURE SURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior.get_sampler_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.load_trace('.pymc_1.trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
